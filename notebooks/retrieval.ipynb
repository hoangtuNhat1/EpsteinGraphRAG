{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Database Create"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✅ Successfully connected to Neo4j!\n"
                    ]
                }
            ],
            "source": [
                "import neo4j\n",
                "from neo4j import GraphDatabase\n",
                "import json\n",
                "from dotenv import load_dotenv\n",
                "import os\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "URI = os.getenv('NEO4J_URI')\n",
                "USERNAME = os.getenv('NEO4J_USERNAME')\n",
                "PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
                "\n",
                "QUESTION = \"Who is Epstein's main target?\"\n",
                "\n",
                "driver = GraphDatabase.driver(URI, auth=(USERNAME, PASSWORD))\n",
                "try:\n",
                "    driver.verify_connectivity()\n",
                "    print(\"✅ Successfully connected to Neo4j!\")\n",
                "except Exception as e:\n",
                "    print(f\"❌ Connection failed: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Vector Search"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from openai import OpenAI\n",
                "from typing import List, Dict, Any\n",
                "\n",
                "client = OpenAI()\n",
                "\n",
                "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
                "    text = text.replace(\"\\n\", \" \")\n",
                "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
                "\n",
                "\n",
                "def embed_texts(texts, model=\"text-embedding-3-small\"):\n",
                "    return [get_embedding(t, model) for t in texts]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def vector_search(query: str, TOP_K = 5) -> List[Dict]:\n",
                "\n",
                "    query_vector = get_embedding(query)\n",
                "\n",
                "    cypher = \"\"\"\n",
                "    CALL db.index.vector.queryNodes(\n",
                "        'event_embedding',\n",
                "        $topK,\n",
                "        $embedding\n",
                "    )\n",
                "    YIELD node, score\n",
                "\n",
                "    MATCH (actor:Entity)-[:PARTICIPATED_IN {role:'actor'}]->(node)\n",
                "    MATCH (target:Entity)-[:PARTICIPATED_IN {role:'target'}]->(node)\n",
                "    OPTIONAL MATCH (node)-[:LOCATED_IN]->(l:Location)\n",
                "    OPTIONAL MATCH (node)-[:HAS_TAG]->(t:Tag)\n",
                "\n",
                "    RETURN\n",
                "        node.id AS event_id,\n",
                "        actor.name AS actor,\n",
                "        node.action AS action,\n",
                "        target.name AS target,\n",
                "        l.name AS location,\n",
                "        node.explicit_topic AS explicit_topic,\n",
                "        collect(DISTINCT t.name) AS tags,\n",
                "        score\n",
                "    ORDER BY score DESC\n",
                "    \"\"\"\n",
                "\n",
                "    with driver.session() as session:\n",
                "        results = session.run(\n",
                "            cypher,\n",
                "            embedding=query_vector,\n",
                "            topK=TOP_K\n",
                "        )\n",
                "\n",
                "        return [dict(record) for record in results]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[{'event_id': 9825,\n",
                            "  'actor': 'Jeffrey Epstein',\n",
                            "  'action': 'maintained relationship with',\n",
                            "  'target': 'multiple billionaires and world leaders',\n",
                            "  'location': 'Manhattan',\n",
                            "  'explicit_topic': 'continued cultivation of high-level relationships',\n",
                            "  'tags': ['Travel Logistics', 'Victim Advocacy', 'Media Strategy'],\n",
                            "  'score': 0.8232795596122742},\n",
                            " {'event_id': 15868,\n",
                            "  'actor': 'Jeffrey Epstein',\n",
                            "  'action': 'identified targets in to',\n",
                            "  'target': 'unknown person A (HOUSE_OVERSIGHT_027281) (HOUSE_OVERSIGHT_027281)',\n",
                            "  'location': None,\n",
                            "  'explicit_topic': 'noting Landowski, Cohen, and Weisselberg are mentioned in complaint',\n",
                            "  'tags': ['Media Coverage', 'Legal Representation'],\n",
                            "  'score': 0.8230377435684204},\n",
                            " {'event_id': 16039,\n",
                            "  'actor': 'Jeffrey Epstein',\n",
                            "  'action': 'clarified political target to',\n",
                            "  'target': 'unknown person A (HOUSE_OVERSIGHT_027346) (HOUSE_OVERSIGHT_027346)',\n",
                            "  'location': None,\n",
                            "  'explicit_topic': 'focus on Charles Koch as primary target rather than David Koch',\n",
                            "  'tags': ['Political Commentary', 'Media Criticism', 'Media Coverage'],\n",
                            "  'score': 0.819682240486145},\n",
                            " {'event_id': 12820,\n",
                            "  'actor': 'Jeffrey Epstein',\n",
                            "  'action': 'discussed regarding',\n",
                            "  'target': \"individuals named Barrack and HBJ as 'stars' of investigation\",\n",
                            "  'location': None,\n",
                            "  'explicit_topic': 'discussing key targets of investigation',\n",
                            "  'tags': ['Media Commentary',\n",
                            "   'Investigative Journalism',\n",
                            "   'Legal Representation'],\n",
                            "  'score': 0.8135155439376831},\n",
                            " {'event_id': 3608,\n",
                            "  'actor': 'Jeffrey Epstein',\n",
                            "  'action': 'deliberately targeted',\n",
                            "  'target': 'disadvantaged girls from single-parent families',\n",
                            "  'location': None,\n",
                            "  'explicit_topic': 'predatory targeting of economically vulnerable youth',\n",
                            "  'tags': ['Mentorship',\n",
                            "   'Personal Relationship',\n",
                            "   'Sexual Assault Allegations'],\n",
                            "  'score': 0.8099218606948853}]"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "vector_search(QUESTION)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import List, Dict\n",
                "\n",
                "\n",
                "def format_events_for_llm(events: List[Dict]) -> str:\n",
                "    \n",
                "    context_blocks = [e['text'] + '\\n' for e in events]\n",
                "    \n",
                "    return \"\\n---\\n\".join(context_blocks)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_answer(question: str, events: List[Dict]) -> str:\n",
                "    context = format_events_for_llm(events)\n",
                "\n",
                "    system_message = \"\"\"You're an Epstein expert, but can only use the \n",
                "    provided documents to respond to the questions.\"\"\"\n",
                "\n",
                "    user_message = f\"\"\"\n",
                "            Use the following documents to answer the question that will follow:\n",
                "            {context}\n",
                "            ---\n",
                "            The question to answer using information only from the above documents:\n",
                "            {question}\"\"\"\n",
                "\n",
                "    stream = client.chat.completions.create(\n",
                "        model=\"gpt-4\",\n",
                "        messages=[\n",
                "            {\"role\": \"system\", \"content\": system_message},\n",
                "            {\"role\": \"user\", \"content\": user_message}\n",
                "        ],\n",
                "        stream=True,\n",
                "    )\n",
                "\n",
                "    for chunk in stream:\n",
                "        print(chunk.choices[0].delta.content or \"\", end=\"\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": [
                "def answer_question(question: str) -> str:\n",
                "    events = vector_search(question)\n",
                "    answer = generate_answer(question, events)\n",
                "    return answer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Jeffrey Epstein owned properties in several locations. These include a ranch in New Mexico, an apartment in Paris, a Caribbean island, a house in Palm Beach, and a property in Manhattan, New York."
                    ]
                }
            ],
            "source": [
                "answer_question(\n",
                "    QUESTION\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Full-text search"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_text_index(tx):\n",
                "    tx.run(\"\"\"\n",
                "        CREATE FULLTEXT INDEX event_text IF NOT EXISTS\n",
                "        FOR (e:Event)\n",
                "        ON EACH [e.text]\n",
                "    \"\"\")\n",
                "with driver.session() as session:\n",
                "    session.execute_write(create_text_index)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 107030 events without embeddings\n",
                        "Added 500 / 107030\n",
                        "Added 1000 / 107030\n",
                        "Added 1500 / 107030\n",
                        "Added 2000 / 107030\n",
                        "Added 2500 / 107030\n",
                        "Added 3000 / 107030\n",
                        "Added 3500 / 107030\n",
                        "Added 4000 / 107030\n",
                        "Added 4500 / 107030\n",
                        "Added 5000 / 107030\n",
                        "Added 5500 / 107030\n",
                        "Added 6000 / 107030\n",
                        "Added 6500 / 107030\n",
                        "Added 7000 / 107030\n",
                        "Added 7500 / 107030\n",
                        "Added 8000 / 107030\n",
                        "Added 8500 / 107030\n",
                        "Added 9000 / 107030\n",
                        "Added 9500 / 107030\n",
                        "Added 10000 / 107030\n",
                        "Added 10500 / 107030\n",
                        "Added 11000 / 107030\n",
                        "Added 11500 / 107030\n",
                        "Added 12000 / 107030\n",
                        "Added 12500 / 107030\n",
                        "Added 13000 / 107030\n",
                        "Added 13500 / 107030\n",
                        "Added 14000 / 107030\n",
                        "Added 14500 / 107030\n",
                        "Added 15000 / 107030\n",
                        "Added 15500 / 107030\n",
                        "Added 16000 / 107030\n",
                        "Added 16500 / 107030\n",
                        "Added 17000 / 107030\n",
                        "Added 17500 / 107030\n",
                        "Added 18000 / 107030\n",
                        "Added 18500 / 107030\n",
                        "Added 19000 / 107030\n",
                        "Added 19500 / 107030\n",
                        "Added 20000 / 107030\n",
                        "Added 20500 / 107030\n",
                        "Added 21000 / 107030\n",
                        "Added 21500 / 107030\n",
                        "Added 22000 / 107030\n",
                        "Added 22500 / 107030\n",
                        "Added 23000 / 107030\n",
                        "Added 23500 / 107030\n",
                        "Added 24000 / 107030\n",
                        "Added 24500 / 107030\n",
                        "Added 25000 / 107030\n",
                        "Added 25500 / 107030\n",
                        "Added 26000 / 107030\n",
                        "Added 26500 / 107030\n",
                        "Added 27000 / 107030\n",
                        "Added 27500 / 107030\n",
                        "Added 28000 / 107030\n",
                        "Added 28500 / 107030\n",
                        "Added 29000 / 107030\n",
                        "Added 29500 / 107030\n",
                        "Added 30000 / 107030\n",
                        "Added 30500 / 107030\n",
                        "Added 31000 / 107030\n",
                        "Added 31500 / 107030\n",
                        "Added 32000 / 107030\n",
                        "Added 32500 / 107030\n",
                        "Added 33000 / 107030\n",
                        "Added 33500 / 107030\n",
                        "Added 34000 / 107030\n",
                        "Added 34500 / 107030\n",
                        "Added 35000 / 107030\n",
                        "Added 35500 / 107030\n",
                        "Added 36000 / 107030\n",
                        "Added 36500 / 107030\n",
                        "Added 37000 / 107030\n",
                        "Added 37500 / 107030\n",
                        "Added 38000 / 107030\n",
                        "Added 38500 / 107030\n",
                        "Added 39000 / 107030\n",
                        "Added 39500 / 107030\n",
                        "Added 40000 / 107030\n",
                        "Added 40500 / 107030\n",
                        "Added 41000 / 107030\n",
                        "Added 41500 / 107030\n",
                        "Added 42000 / 107030\n",
                        "Added 42500 / 107030\n",
                        "Added 43000 / 107030\n",
                        "Added 43500 / 107030\n",
                        "Added 44000 / 107030\n",
                        "Added 44500 / 107030\n",
                        "Added 45000 / 107030\n",
                        "Added 45500 / 107030\n",
                        "Added 46000 / 107030\n",
                        "Added 46500 / 107030\n",
                        "Added 47000 / 107030\n",
                        "Added 47500 / 107030\n",
                        "Added 48000 / 107030\n",
                        "Added 48500 / 107030\n",
                        "Added 49000 / 107030\n",
                        "Added 49500 / 107030\n",
                        "Added 50000 / 107030\n",
                        "Added 50500 / 107030\n",
                        "Added 51000 / 107030\n",
                        "Added 51500 / 107030\n",
                        "Added 52000 / 107030\n",
                        "Added 52500 / 107030\n",
                        "Added 53000 / 107030\n",
                        "Added 53500 / 107030\n",
                        "Added 54000 / 107030\n",
                        "Added 54500 / 107030\n",
                        "Added 55000 / 107030\n",
                        "Added 55500 / 107030\n",
                        "Added 56000 / 107030\n",
                        "Added 56500 / 107030\n",
                        "Added 57000 / 107030\n",
                        "Added 57500 / 107030\n",
                        "Added 58000 / 107030\n",
                        "Added 58500 / 107030\n",
                        "Added 59000 / 107030\n",
                        "Added 59500 / 107030\n",
                        "Added 60000 / 107030\n",
                        "Added 60500 / 107030\n",
                        "Added 61000 / 107030\n",
                        "Added 61500 / 107030\n",
                        "Added 62000 / 107030\n",
                        "Added 62500 / 107030\n",
                        "Added 63000 / 107030\n",
                        "Added 63500 / 107030\n",
                        "Added 64000 / 107030\n",
                        "Added 64500 / 107030\n",
                        "Added 65000 / 107030\n",
                        "Added 65500 / 107030\n",
                        "Added 66000 / 107030\n",
                        "Added 66500 / 107030\n",
                        "Added 67000 / 107030\n",
                        "Added 67500 / 107030\n",
                        "Added 68000 / 107030\n",
                        "Added 68500 / 107030\n",
                        "Added 69000 / 107030\n",
                        "Added 69500 / 107030\n",
                        "Added 70000 / 107030\n",
                        "Added 70500 / 107030\n",
                        "Added 71000 / 107030\n",
                        "Added 71500 / 107030\n",
                        "Added 72000 / 107030\n",
                        "Added 72500 / 107030\n",
                        "Added 73000 / 107030\n",
                        "Added 73500 / 107030\n",
                        "Added 74000 / 107030\n",
                        "Added 74500 / 107030\n",
                        "Added 75000 / 107030\n",
                        "Added 75500 / 107030\n",
                        "Added 76000 / 107030\n",
                        "Added 76500 / 107030\n",
                        "Added 77000 / 107030\n",
                        "Added 77500 / 107030\n",
                        "Added 78000 / 107030\n",
                        "Added 78500 / 107030\n",
                        "Added 79000 / 107030\n",
                        "Added 79500 / 107030\n",
                        "Added 80000 / 107030\n",
                        "Added 80500 / 107030\n",
                        "Added 81000 / 107030\n",
                        "Added 81500 / 107030\n",
                        "Added 82000 / 107030\n",
                        "Added 82500 / 107030\n",
                        "Added 83000 / 107030\n",
                        "Added 83500 / 107030\n",
                        "Added 84000 / 107030\n",
                        "Added 84500 / 107030\n",
                        "Added 85000 / 107030\n",
                        "Added 85500 / 107030\n",
                        "Added 86000 / 107030\n",
                        "Added 86500 / 107030\n",
                        "Added 87000 / 107030\n",
                        "Added 87500 / 107030\n",
                        "Added 88000 / 107030\n",
                        "Added 88500 / 107030\n",
                        "Added 89000 / 107030\n",
                        "Added 89500 / 107030\n",
                        "Added 90000 / 107030\n",
                        "Added 90500 / 107030\n",
                        "Added 91000 / 107030\n",
                        "Added 91500 / 107030\n",
                        "Added 92000 / 107030\n",
                        "Added 92500 / 107030\n",
                        "Added 93000 / 107030\n",
                        "Added 93500 / 107030\n",
                        "Added 94000 / 107030\n",
                        "Added 94500 / 107030\n",
                        "Added 95000 / 107030\n",
                        "Added 95500 / 107030\n",
                        "Added 96000 / 107030\n",
                        "Added 96500 / 107030\n",
                        "Added 97000 / 107030\n",
                        "Added 97500 / 107030\n",
                        "Added 98000 / 107030\n",
                        "Added 98500 / 107030\n",
                        "Added 99000 / 107030\n",
                        "Added 99500 / 107030\n",
                        "Added 100000 / 107030\n",
                        "Added 100500 / 107030\n",
                        "Added 101000 / 107030\n",
                        "Added 101500 / 107030\n",
                        "Added 102000 / 107030\n",
                        "Added 102500 / 107030\n",
                        "Added 103000 / 107030\n",
                        "Added 103500 / 107030\n",
                        "Added 104000 / 107030\n",
                        "Added 104500 / 107030\n",
                        "Added 105000 / 107030\n",
                        "Added 105500 / 107030\n",
                        "Added 106000 / 107030\n",
                        "Added 106500 / 107030\n",
                        "Added 107000 / 107030\n",
                        "Added 107030 / 107030\n",
                        "✅ All texts stored.\n"
                    ]
                }
            ],
            "source": [
                "def store_text(tx, event_id, text):\n",
                "    tx.run(\n",
                "        \"\"\"\n",
                "        MATCH (e:Event {id:$id})\n",
                "        SET e.text = $text\n",
                "        \"\"\",\n",
                "        id=event_id,\n",
                "        text=text\n",
                "    )\n",
                "\n",
                "def add_event_text():\n",
                "\n",
                "    with driver.session() as session:\n",
                "        records = session.execute_read(fetch_events)\n",
                "\n",
                "    print(f\"Found {len(records)} events\")\n",
                "\n",
                "    BATCH_SIZE = 500\n",
                "    \n",
                "    for i in range(0, len(records), BATCH_SIZE):\n",
                "\n",
                "        batch = records[i:i+BATCH_SIZE]\n",
                "\n",
                "        texts = [\n",
                "            build_event_text(dict(r))\n",
                "            for r in batch\n",
                "        ]\n",
                "\n",
                "        with driver.session() as session:\n",
                "            for record, text in zip(batch, texts):\n",
                "                session.execute_write(\n",
                "                    store_text,\n",
                "                    record[\"id\"],\n",
                "                    text\n",
                "                )\n",
                "\n",
                "        print(f\"Added {i + len(batch)} / {len(records)}\")\n",
                "\n",
                "    driver.close()\n",
                "    print(\"✅ All texts stored.\")\n",
                "\n",
                "\n",
                "add_event_text()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "def hybrid_search(query: str, TOP_K = 5) -> List[Dict]:\n",
                "\n",
                "    query_vector = get_embedding(query)\n",
                "\n",
                "    HYBRID_QUERY = \"\"\"\n",
                "    CALL {\n",
                "        // Vector index\n",
                "        CALL db.index.vector.queryNodes('event_embedding', $k, $embedding)\n",
                "        YIELD node, score\n",
                "        WITH collect({node: node, score: score}) AS nodes, max(score) AS max\n",
                "        UNWIND nodes AS n\n",
                "        RETURN n.node AS node, (n.score / max) AS score\n",
                "\n",
                "        UNION\n",
                "\n",
                "        // Fulltext index\n",
                "        CALL db.index.fulltext.queryNodes('event_text', $q, {limit: $k})\n",
                "        YIELD node, score\n",
                "        WITH collect({node: node, score: score}) AS nodes, max(score) AS max\n",
                "        UNWIND nodes AS n\n",
                "        RETURN n.node AS node, (n.score / max) AS score\n",
                "    }\n",
                "\n",
                "    // Deduplicate + rerank\n",
                "    WITH node, max(score) AS score\n",
                "    ORDER BY score DESC\n",
                "    LIMIT $k\n",
                "\n",
                "    RETURN\n",
                "        node.id AS id,\n",
                "        node.text AS text,\n",
                "        score\n",
                "    \"\"\"\n",
                "    \n",
                "    with driver.session() as session:\n",
                "        results = session.run(\n",
                "            HYBRID_QUERY,\n",
                "            q=query,\n",
                "            embedding=query_vector,\n",
                "            k=TOP_K,\n",
                "        )\n",
                "\n",
                "        return [dict(r) for r in results]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[{'id': 9825,\n",
                            "  'text': 'Jeffrey Epstein maintained relationship with multiple billionaires and world leaders. Location: Manhattan. Topic: continued cultivation of high-level relationships. Context: persistence_of_influence_despite_criminal_conviction.',\n",
                            "  'score': 1.0},\n",
                            " {'id': 48834,\n",
                            "  'text': 'Don Marquis said A hypocrite is a person who— but who isn’t?. Topic: philosophical quotation on hypocrisy. Context: providing reflective commentary.',\n",
                            "  'score': 1.0},\n",
                            " {'id': 15868,\n",
                            "  'text': 'Jeffrey Epstein identified targets in to unknown person A (HOUSE_OVERSIGHT_027281) (HOUSE_OVERSIGHT_027281). Topic: noting Landowski, Cohen, and Weisselberg are mentioned in complaint. Context: tracking who faces legal exposure from Trump Foundation litigation.',\n",
                            "  'score': 0.9997062771193206},\n",
                            " {'id': 16039,\n",
                            "  'text': 'Jeffrey Epstein clarified political target to unknown person A (HOUSE_OVERSIGHT_027346) (HOUSE_OVERSIGHT_027346). Topic: focus on Charles Koch as primary target rather than David Koch. Context: strategic clarification of main political opponent.',\n",
                            "  'score': 0.9956305011048454},\n",
                            " {'id': 12820,\n",
                            "  'text': \"Jeffrey Epstein discussed regarding individuals named Barrack and HBJ as 'stars' of investigation. Topic: discussing key targets of investigation. Context: assessing who faces criminal exposure in ongoing probes.\",\n",
                            "  'score': 0.9881400970538009}]"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "hybrid_search(QUESTION)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step-back prompting"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "stepback_system_message = f\"\"\" \n",
                "You are an expert at world knowledge. Your task is to step back\n",
                "and paraphrase a question to a more generic step-back question, which\n",
                "is easier to answer. Here are a few examples\n",
                " \n",
                "\"input\": \"Could the members of The Police perform lawful arrests?\"\n",
                "\"output\": \"what can the members of The Police do?\"\n",
                "\n",
                "\"input\": \"Jefferey Epstein’s was born in what country?\"\n",
                "\"output\": \"what is Jefferey Epstein’s personal history?\"\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_stepback(question: str):\n",
                "    user_message = f\"\"\"{question}\"\"\"\n",
                "    step_back_question = client.responses.create(\n",
                "        model=\"gpt-5-mini\",\n",
                "        input=[\n",
                "            {\"role\": \"system\", \"content\": stepback_system_message},\n",
                "            {\"role\": \"user\", \"content\": user_message},\n",
                "        ]\n",
                "    ).output_text\n",
                "    return step_back_question"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Stepback results: what kinds of people did Epstein target?\n"
                    ]
                }
            ],
            "source": [
                "step_back_question = generate_stepback(QUESTION)\n",
                "print(f\"Stepback results: {step_back_question}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [],
            "source": [
                "def rag_pipeline(question: str) -> str:\n",
                "    stepback_prompt = generate_stepback(question)\n",
                "    print(stepback_prompt)\n",
                "    events = hybrid_search(stepback_prompt)\n",
                "    print(events)\n",
                "    answer = generate_answer(question, events)\n",
                "    return answer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "what types of people did Jeffrey Epstein target?\n",
                        "[{'id': 3608, 'text': 'Jeffrey Epstein deliberately targeted disadvantaged girls from single-parent families. Topic: predatory targeting of economically vulnerable youth. Context: exploitation of social inequality and poverty.', 'score': 1.0}, {'id': 55920, 'text': 'M. Hoffman coauthored Cooperate without looking: Why we care what people think and not just what they do. Topic: study of cooperation based on perceived thoughts. Context: exploration of social influence on behavior.', 'score': 1.0}, {'id': 33285, 'text': 'Jeffrey Epstein exploited through connections and shared with adult male peers including royalty, politicians, academicians, businessmen. Topic: trafficking victim to high-level powerful individuals. Context: leveraging victim for networking and influence cultivation.', 'score': 0.9752890527647559}, {'id': 48044, 'text': 'Jeffrey Epstein enjoys social life with young women. Topic: documented preference for socializing with young women. Context: predatory behavior pattern and normalization by media figure.', 'score': 0.9752090462868566}, {'id': 43611, 'text': 'Jeffrey Epstein characterized as enjoying social relationships with younger women. Topic: documented pattern of social behavior with young women. Context: public awareness of controversial personal preferences.', 'score': 0.9712643400211748}]\n",
                        "Epstein's main target, as indicated by the documents, is disadvantaged girls from single-parent families."
                    ]
                }
            ],
            "source": [
                "rag_pipeline(QUESTION)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Text to Cypher"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_structured_schema(driver: neo4j.Driver) -> Dict[str, Any]:\n",
                "\n",
                "    NODE_PROPERTIES_QUERY = \"\"\"\n",
                "    CALL apoc.meta.data()\n",
                "    YIELD label, other, elementType, type, property\n",
                "    WHERE NOT type = \"RELATIONSHIP\" AND elementType = \"node\"\n",
                "    WITH label AS nodeLabels, collect({property:property, type:type}) AS properties\n",
                "    RETURN {labels: nodeLabels, properties: properties} AS output\n",
                "    \"\"\"\n",
                "    REL_PROPERTIES_QUERY = \"\"\"\n",
                "    CALL apoc.meta.data()\n",
                "    YIELD label, other, elementType, type, property\n",
                "    WHERE NOT type = \"RELATIONSHIP\" AND elementType = \"relationship\"\n",
                "    WITH label AS relType, collect({property:property, type:type}) AS properties\n",
                "    RETURN {type: relType, properties: properties} AS output\n",
                "    \"\"\"\n",
                "    REL_QUERY = \"\"\"\n",
                "    CALL apoc.meta.data()\n",
                "    YIELD label, other, elementType, type, property\n",
                "    WHERE type = \"RELATIONSHIP\" AND elementType = \"node\"\n",
                "    UNWIND other AS other_node\n",
                "    RETURN {start: label, type: property, end: toString(other_node)} AS output\n",
                "    \"\"\"\n",
                "\n",
                "    def _run_query(session, q):\n",
                "        return [rec.get(\"output\") for rec in session.run(q)]\n",
                "\n",
                "    with driver.session() as session:\n",
                "        node_properties = _run_query(session, NODE_PROPERTIES_QUERY)\n",
                "        rel_properties = _run_query(session, REL_PROPERTIES_QUERY)\n",
                "        relationships = _run_query(session, REL_QUERY)\n",
                "\n",
                "    node_props = {el[\"labels\"]: el[\"properties\"] for el in node_properties if el}\n",
                "    rel_props = {el[\"type\"]: el[\"properties\"] for el in rel_properties if el}\n",
                "\n",
                "    return {\n",
                "        \"node_props\": node_props,\n",
                "        \"rel_props\": rel_props,\n",
                "        \"relationships\": relationships,\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_schema(structured_schema: Dict[str, Any]) -> str:\n",
                "    def _format_props(props: List[Dict[str, Any]]) -> str:\n",
                "        return \", \".join(f\"{prop['property']}: {prop['type']}\" for prop in props)\n",
                "\n",
                "    formatted_node_props = [\n",
                "        f\"{label} {{{_format_props(props)}}}\"\n",
                "        for label, props in structured_schema.get(\"node_props\", {}).items()\n",
                "    ]\n",
                "\n",
                "    formatted_rel_props = [\n",
                "        f\"{rel_type} {{{_format_props(props)}}}\"\n",
                "        for rel_type, props in structured_schema.get(\"rel_props\", {}).items()\n",
                "    ]\n",
                "\n",
                "    formatted_rels = [\n",
                "        f\"(:{element['start']})-[:{element['type']}]->(:{element['end']})\"\n",
                "        for element in structured_schema.get(\"relationships\", [])\n",
                "    ]\n",
                "\n",
                "    return \"\\n\".join(\n",
                "        [\n",
                "            \"Node labels and properties:\",\n",
                "            \"\\n\".join(formatted_node_props) if formatted_node_props else \"  (none)\",\n",
                "            \"Relationship types and properties:\",\n",
                "            \"\\n\".join(formatted_rel_props) if formatted_rel_props else \"  (none)\",\n",
                "            \"The relationships:\",\n",
                "            \"\\n\".join(formatted_rels) if formatted_rels else \"  (none)\",\n",
                "        ]\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'Node labels and properties:\\nEntity {name: STRING}\\nEvent {timestamp: STRING, text: STRING, created_at: DATE_TIME, embedding: LIST, sequence_order: INTEGER, explicit_topic: STRING, implicit_topic: STRING, id: INTEGER, action: STRING}\\nDocument {doc_id: STRING}\\nTag {name: STRING}\\nLocation {name: STRING}\\nRelationship types and properties:\\nPARTICIPATED_IN {role: STRING}\\nThe relationships:\\n(:Entity)-[:PARTICIPATED_IN]->(:Event)\\n(:Event)-[:FROM_DOCUMENT]->(:Document)\\n(:Event)-[:HAS_TAG]->(:Tag)\\n(:Event)-[:LOCATED_IN]->(:Location)'"
                        ]
                    },
                    "execution_count": 39,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "get_schema(get_structured_schema(driver))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt_template = \"\"\"\n",
                "Instructions:\n",
                "Generate Cypher statement to query a graph database to get the data to answer \n",
                "the following user question.\n",
                "Graph database schema:\n",
                "Use only the provided relationship types and properties in the schema.\n",
                "Do not use any other relationship types or properties that are not provided in \n",
                "the schema.\n",
                "{schema}\n",
                "Terminology mapping:\n",
                "This section is helpful to map terminology between the user question and the \n",
                "graph database schema.\n",
                "{terminology}\n",
                "Examples:\n",
                "The following examples provide useful patterns for querying the graph database.\n",
                "{examples}\n",
                "Format instructions:\n",
                "Do not include any explanations or apologies in your responses.\n",
                "Do not respond to any questions that might ask anything else than for you to\n",
                "construct a Cypher statement.\n",
                "Do not include any text except the generated Cypher statement.\n",
                "ONLY RESPOND WITH CYPHER—NO CODE BLOCKS.\n",
                "User question: {question}\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Instructions:\n",
                        "Generate Cypher statement to query a graph database to get the data to answer \n",
                        "the following user question.\n",
                        "Graph database schema:\n",
                        "Use only the provided relationship types and properties in the schema.\n",
                        "Do not use any other relationship types or properties that are not provided in \n",
                        "the schema.\n",
                        "Node labels and properties:\n",
                        "Entity {name: STRING}\n",
                        "Event {timestamp: STRING, embedding: LIST, text: STRING, created_at: DATE_TIME, id: INTEGER, implicit_topic: STRING, explicit_topic: STRING, action: STRING, sequence_order: INTEGER}\n",
                        "Document {doc_id: STRING}\n",
                        "Tag {name: STRING}\n",
                        "Location {name: STRING}\n",
                        "Relationship types and properties:\n",
                        "PARTICIPATED_IN {role: STRING}\n",
                        "The relationships:\n",
                        "(:Entity)-[:PARTICIPATED_IN]->(:Event)\n",
                        "(:Event)-[:FROM_DOCUMENT]->(:Document)\n",
                        "(:Event)-[:HAS_TAG]->(:Tag)\n",
                        "(:Event)-[:LOCATED_IN]->(:Location)\n",
                        "Terminology mapping:\n",
                        "This section is helpful to map terminology between the user question and the \n",
                        "graph database schema.\n",
                        "\n",
                        "Entities:  When a user asks about a person by trade like politician, celebrity, millionaire, or criminal, they are referring to a node with the label 'Entity'.\n",
                        "Location: When a user asks about places.\n",
                        "\n",
                        "Examples:\n",
                        "The following examples provide useful patterns for querying the graph database.\n",
                        "Question: Who are the two people interated in most event together?\n",
                        "Cypher: MATCH (p1:Entity)-[:PARTICIPATED_IN]->(e:Event)<-[:PARTICIPATED_IN]-(p2:Entity) WHERE p1 <> p2 RETURN p1.name, p2.name, COUNT(e) AS EVENT_COUNT ORDER BY EVENT_COUNT DESC LIMIT 1\n",
                        "Format instructions:\n",
                        "Do not include any explanations or apologies in your responses.\n",
                        "Do not respond to any questions that might ask anything else than for you to\n",
                        "construct a Cypher statement.\n",
                        "Do not include any text except the generated Cypher statement.\n",
                        "ONLY RESPOND WITH CYPHER—NO CODE BLOCKS.\n",
                        "User question: Who is Epstein's main target?\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "structured_schema = get_structured_schema(driver)\n",
                "schema_string = get_schema(structured_schema)\n",
                "\n",
                "terminology_string = \"\"\"\n",
                "Entities:  When a user asks about a person by trade like politician, celebrity, millionaire, or criminal, they are referring to a node with the label 'Entity'.\n",
                "Location: When a user asks about places.\n",
                "\"\"\"\n",
                "\n",
                "examples = [\n",
                "    (\n",
                "        \"Who are the two people interated in most event together?\",\n",
                "        \"MATCH (p1:Entity)-[:PARTICIPATED_IN]->(e:Event)<-[:PARTICIPATED_IN]-(p2:Entity) \"\n",
                "        \"WHERE p1 <> p2 RETURN p1.name, p2.name, COUNT(e) AS EVENT_COUNT \"\n",
                "        \"ORDER BY EVENT_COUNT DESC LIMIT 1\"\n",
                "    )\n",
                "]\n",
                "\n",
                "examples_text = \"\\n\".join(f\"Question: {q}\\nCypher: {c}\" for q, c in examples)\n",
                "\n",
                "full_prompt = prompt_template.format(\n",
                "    question=QUESTION,\n",
                "    schema=schema_string,\n",
                "    terminology=terminology_string,\n",
                "    examples=examples_text,\n",
                ")\n",
                "\n",
                "print(full_prompt)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'MATCH (ep:Entity)-[r1:PARTICIPATED_IN]->(ev:Event)<-[r2:PARTICIPATED_IN]-(t:Entity)\\nWHERE toLower(ep.name) CONTAINS \"epstein\" AND r2.role = \"target\" AND t <> ep\\nRETURN t.name AS target_name, COUNT(ev) AS event_count\\nORDER BY event_count DESC\\nLIMIT 1'"
                        ]
                    },
                    "execution_count": 45,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "def generate_cypher(prompt: str):\n",
                "    step_back_question = client.responses.create(\n",
                "        model=\"gpt-5-mini\",\n",
                "        input=[\n",
                "            {\"role\": \"system\", \"content\": stepback_system_message},\n",
                "            {\"role\": \"user\", \"content\": prompt},\n",
                "        ]\n",
                "    ).output_text\n",
                "    return step_back_question\n",
                "generate_cypher(full_prompt)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
